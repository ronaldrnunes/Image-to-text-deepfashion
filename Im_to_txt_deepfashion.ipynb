{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QdqaXbuLiQ1a"
      },
      "source": [
        "# Problema Abordado"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9AhBEMWDUmAW"
      },
      "source": [
        "# Implementação"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZOmiCXs8T7mx"
      },
      "source": [
        "## Importações"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "7bNllyRyT_2Q"
      },
      "outputs": [
        {
          "ename": "ImportError",
          "evalue": "cannot import name 'models' from 'torchvision.models' (C:\\Users\\User\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torchvision\\models\\__init__.py)",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[1], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorchvision\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m transforms, datasets\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorchvision\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m models\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m GPT2Tokenizer, GPT2LMHeadModel\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DataLoader, Dataset\n",
            "\u001b[1;31mImportError\u001b[0m: cannot import name 'models' from 'torchvision.models' (C:\\Users\\User\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torchvision\\models\\__init__.py)"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from torchvision import transforms, datasets\n",
        "from torchvision.models import models\n",
        "from transformers import GPT2Tokenizer, GPT2LMHeadModel\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from datasets import load_dataset\n",
        "from PIL import Image\n",
        "import os\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9uMtEMsuchLL"
      },
      "source": [
        "##Funções Auxiliares"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aypah2WacsEP"
      },
      "outputs": [],
      "source": [
        "def train_model(\n",
        "    model,          # Seu modelo\n",
        "    train_loader,   # DataLoader de treino\n",
        "    criterion,      # Função de perda\n",
        "    optimizer,      # Otimizador\n",
        "    device,         # \"cuda\" ou \"cpu\"\n",
        "    epochs=10       # Número de épocas\n",
        "):\n",
        "    model.to(device)\n",
        "    model.train()  # Modo treino\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        epoch_loss = 0.0\n",
        "\n",
        "        for images, captions in train_loader:\n",
        "\n",
        "            images = images.to(device)\n",
        "            captions = captions.to(device)\n",
        "\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "\n",
        "            outputs = model(images, captions[:, :-1])\n",
        "            loss = criterion(\n",
        "                outputs.view(-1, outputs.size(-1)),\n",
        "                captions[:, 1:].reshape(-1)\n",
        "            )\n",
        "\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            epoch_loss += loss.item()\n",
        "\n",
        "        # Loss médio da época\n",
        "        avg_loss = epoch_loss / len(train_loader)\n",
        "        print(f\"Epoch {epoch+1}/{epochs} - Loss: {avg_loss:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224,224)), # Padrão dos modelos pretreinados do ImageNet\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean = [0.485, 0.456, 0.406],  ## Normalizando dados no padrão do ImageNet\n",
        "                         std=[0.229, 0.224, 0.225])\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# def buildDeepFashionDataset(labelDataset):\n",
        "\n",
        "#     for path in labelDataset['path']:\n",
        "#         img_path = f'/datasets/selected_images/{path}'\n",
        "#         image = Image.open(img_path).convert(\"RGB\")\n",
        "#         transformed_image = transform(image)\n",
        "        \n",
        "#         print(transformed_image)\n",
        "    "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "39mL4ikCiW_a"
      },
      "source": [
        "## Dados"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bBiPU36gWSSU"
      },
      "source": [
        "###Carregando o dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {},
      "outputs": [],
      "source": [
        "class DeepFashionDataset(Dataset):\n",
        "    def __init__(self, labelDataset, image_dir, transform=None, tokenizer=None, max_length=30):\n",
        "        self.df = labelDataset.reset_index(drop=True)\n",
        "        self.image_dir = image_dir\n",
        "        self.transform = transform\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_length = max_length\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        # --- Imagem ---\n",
        "        row = self.df.iloc[idx]\n",
        "        img_path = os.path.join(self.image_dir, row['path'])\n",
        "        image = Image.open(img_path).convert(\"RGB\")\n",
        "\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        # --- Texto ---\n",
        "        caption = row['caption']\n",
        "        if self.tokenizer:\n",
        "            tokens = self.tokenizer(caption, padding=\"max_length\", truncation=True,\n",
        "                                    max_length=self.max_length, return_tensors=\"pt\")\n",
        "            input_ids = tokens[\"input_ids\"].squeeze(0)\n",
        "            attention_mask = tokens[\"attention_mask\"].squeeze(0)\n",
        "        else:\n",
        "            input_ids = caption\n",
        "            attention_mask = None\n",
        "\n",
        "        return {\n",
        "            \"image\": image,\n",
        "            \"input_ids\": 'input_ids',\n",
        "            \"attention_mask\": 'attention_mask'\n",
        "        }\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OA59r0s1VVUB",
        "outputId": "b52cbe8f-692d-42f2-b321-ea0d738f4b94"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 12278 entries, 0 to 12277\n",
            "Data columns (total 7 columns):\n",
            " #   Column        Non-Null Count  Dtype \n",
            "---  ------        --------------  ----- \n",
            " 0   image_id      12278 non-null  object\n",
            " 1   caption       12278 non-null  object\n",
            " 2   path          12278 non-null  object\n",
            " 3   gender        12278 non-null  object\n",
            " 4   product_type  12278 non-null  object\n",
            " 5   product_id    12278 non-null  object\n",
            " 6   image_type    12278 non-null  object\n",
            "dtypes: object(7)\n",
            "memory usage: 671.6+ KB\n"
          ]
        }
      ],
      "source": [
        "labels_df = pd.read_csv('datasets/labels_front.csv')\n",
        "labels_df.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9qla7QbiWDzk"
      },
      "source": [
        "### Data Loader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {},
      "outputs": [],
      "source": [
        "dataset = DeepFashionDataset(\n",
        "    labelDataset = labels_df,\n",
        "    image_dir = \"datasets/selected_images\",\n",
        "    transform = transform\n",
        "    # tokenizer = tokenizer\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {},
      "outputs": [],
      "source": [
        "batch_size = 64\n",
        "train_loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
        "test_loader = DataLoader(dataset, batch_size=batch_size, shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# img_path = 'datasets/selected_images/MEN-Denim-id_00000089-28_1_front.jpg'\n",
        "# image = Image.open(img_path).convert(\"RGB\")\n",
        "\n",
        "# transform = transforms.Compose([\n",
        "#     transforms.Resize((224,224)), # Padrão dos modelos pretreinados de CNN do ImageNet. Esse tamanho pode ser modificado com base na nossa CNN\n",
        "#     transforms.ToTensor(),  # Converte para tensor [C, H, W] , float32 e normalizado [0, 1]\n",
        "#     transforms.Normalize(mean = [0.485, 0.456, 0.406],  ## Normalizando dados no padrão do ImageNet\n",
        "#                          std=[0.229, 0.224, 0.225])\n",
        "# ])\n",
        "\n",
        "# print(transform(image)) #aplicando transformações e adiciona dimensão de batch: shape vira (1, 3, 224, 224)\n",
        "\n",
        " "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LnpjZSgZiWi2"
      },
      "source": [
        "## Rede Implementada"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oAzQW_y3a2Vw"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "class ImageToText(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "        # Encoder (CNN - Custom)\n",
        "        super().__init__()\n",
        "        \n",
        "        self.encoder = models.resnet50(pretrained=True)\n",
        "        self.encoder.fc = nn.Identity()  \n",
        "        \n",
        "\n",
        "\n",
        "        # Decoder (GPT2)\n",
        "\n",
        "\n",
        "    def forward(self,):\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M9NpecFBiXTH"
      },
      "source": [
        "# Treinamento da Rede"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ukwVKsITiXrC"
      },
      "source": [
        "# Qualidade dos Resultados"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TWUsn09Ei0V0"
      },
      "source": [
        "# Discussão Geral"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
